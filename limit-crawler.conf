# include this inside http { inside your nginx.conf like:
# include /etc/nginx/nginx-limit-crawlers/limit-crawler.conf;

# Define a map to check the User-Agent header for known AI bots.
map $http_user_agent $crawler_bot {
        default 0;

# List of AI bot patterns (case-insensitive match)
# from https://github.com/kurren/ai-bots-crawlers/blob/main/map%20directive on 11-Mar-2025
        ~*AnthropicAI   1;
        ~*OpenAI                1;
        ~*Sogou                 1;
        ~*AhrefsBot             1;
        ~*SemrushBot    1;
        ~*ia_archiver   1;
        ~*AI2Bot                1;
        ~*Ai2Bot-Dolma  1;
        ~*Amazonbot             1;
        ~*anthropic-ai  1;
        ~*Applebot              1;
        ~*Applebot-Extended 1;
        ~*Bytespider    1;
        ~*CCBot         1;
        ~*ChatGPT-User  1;
        ~*Claude-Web 1;
        ~*ClaudeBot 1;
        ~*cohere-ai 1;
        ~*cohere-training-data-crawler 1;
        ~*Crawlspace 1;
        ~*Diffbot 1;
        ~*DuckAssistBot 1;
        ~*FacebookBot 1;
        ~*FriendlyCrawler 1;
        ~*Google-Extended 1;
        ~*GoogleOther 1;
        ~*GoogleOther-Image 1;
        ~*GoogleOther-Video 1;
        ~*GPTBot 1;
        ~*iaskspider/2.0 1;
        ~*ICC-Crawler 1;
        ~*ImagesiftBot 1;
        ~*img2dataset 1;
        ~*ISSCyberRiskCrawler 1;
        ~*Kangaroo\sBot 1;
        ~*Meta-ExternalAgent 1;
        ~*Meta-ExternalFetcher 1;
        ~*OAI-SearchBot 1;
        ~*omgili 1;
        ~*omgilibot 1;
        ~*PanguBot 1;
        ~*PerplexityBot 1;
        ~*PetalBot 1;
        ~*Scrapy 1;
        ~*SemrushBot-OCOB 1;
        ~*SemrushBot-SWA 1;
        ~*Sidetrade\sindexer\sbot 1;
        ~*Timpibot 1;
        ~*VelenPublicWebCrawler 1;
        ~*Webzio-Extended       1;
        ~*YouBot                1;

        # added by moparisthebest from his access logs
        ~*BLEXBot 1;
        ~*DataForSeoBot 1;
        ~*DotBot 1;
        ~*Aliyun 1;
        ~*CDSCbot 1;
        ~*Gaisbot 1;
        ~*Googlebot-Image 1;
        ~*Google-Display-Ads-Bot 1;
        ~*GulperBot 1;
        ~*BacklinksExtendedBot 1;
        ~*BitSightBot 1;
        ~*MetaJobBot 1;
        ~*MJ12bot 1;
        ~*Twitter 1;
        ~*facebook 1;
        ~*VirusTotalBot 1;
        ~*SummalyBot 1;
        ~*Spider_Bot 1;
        ~*Who.is\sBot 1;
        ~*ws-bot-v1 1;
        ~*boot-bot-rs 1;
        ~*yacybot 1;
        ~*ZoomBot 1;
        ~*Barkrowler 1;
        ~*SeznamBot 1;
        ~*VelenPublicWebCrawler 1;
        ~*ev-crawler 1;
        ~*netEstate\sNE\sCrawler 1;
        ~*DuckDuckBot 1;
        ~*Googlebot 1;
        ~*AhrefsBot 1;
        ~*AwarioBot 1;
        ~*Discordbot 1;
        ~*MojeekBot 1;
        ~*Qwantbot 1;
        ~*Yandex 1;
        ~*archive.org_bot 1;
        ~*coccocbot 1;
        ~*keys-so-bot 1;
        ~*perplexity\.ai 1;
        ~*bingbot 1;
        ~*Slack-ImgProxy 1;
}

map $crawler_bot $crawler_bot_ip_key {
    0 "";
    1 $binary_remote_addr;
}

map $crawler_bot $crawler_bot_ua_key {
    0 "";
    1 $http_user_agent;
}

limit_req_zone $crawler_bot_ip_key zone=crawlip:10m rate=5r/m; # 5 requests per minute
limit_req zone=crawlip nodelay;
limit_req_zone $crawler_bot_ua_key zone=crawlua:10m rate=5r/m; # 5 requests per minute
limit_req zone=crawlua nodelay;

# limit_req_status 503; # default, service unavailable
limit_req_status 429; # too many requests
