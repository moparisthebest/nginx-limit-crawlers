# include this inside http { inside your nginx.conf like:
# include /etc/nginx/nginx-limit-crawlers/limit-crawler.conf;

# Define a map to check the User-Agent header for known AI bots.
map $http_user_agent $crawler_bot {
        default 0;

# List of AI bot patterns (case-insensitive match)
# from https://github.com/kurren/ai-bots-crawlers/blob/main/map%20directive on 11-Mar-2025
        ~*AnthropicAI   1;
        ~*OpenAI                1;
        ~*Sogou                 1;
        ~*AhrefsBot             1;
        ~*SemrushBot    1;
        ~*ia_archiver   1;
        ~*AI2Bot                1;
        ~*Ai2Bot-Dolma  1;
        ~*Amazonbot             1;
        ~*anthropic-ai  1;
        ~*Applebot              1;
        ~*Applebot-Extended 1;
        ~*Bytespider    1;
        ~*CCBot         1;
        ~*ChatGPT-User  1;
        ~*Claude-Web 1;
        ~*ClaudeBot 1;
        ~*cohere-ai 1;
        ~*cohere-training-data-crawler 1;
        ~*Crawlspace 1;
        ~*Diffbot 1;
        ~*DuckAssistBot 1;
        ~*FacebookBot 1;
        ~*FriendlyCrawler 1;
        ~*Google-Extended 1;
        ~*GoogleOther 1;
        ~*GoogleOther-Image 1;
        ~*GoogleOther-Video 1;
        ~*GPTBot 1;
        ~*iaskspider/2.0 1;
        ~*ICC-Crawler 1;
        ~*ImagesiftBot 1;
        ~*img2dataset 1;
        ~*ISSCyberRiskCrawler 1;
        ~*Kangaroo\sBot 1;
        ~*Meta-ExternalAgent 1;
        ~*Meta-ExternalFetcher 1;
        ~*OAI-SearchBot 1;
        ~*omgili 1;
        ~*omgilibot 1;
        ~*PanguBot 1;
        ~*PerplexityBot 1;
        ~*PetalBot 1;
        ~*Scrapy 1;
        ~*SemrushBot-OCOB 1;
        ~*SemrushBot-SWA 1;
        ~*Sidetrade\sindexer\sbot 1;
        ~*Timpibot 1;
        ~*VelenPublicWebCrawler 1;
        ~*Webzio-Extended       1;
        ~*YouBot                1;

        # added by moparisthebest from his access logs
        ~*BLEXBot 1;
        ~*DataForSeoBot 1;
}

map $crawler_bot $crawler_bot_ip_key {
    0 "";
    1 $binary_remote_addr;
}

map $crawler_bot $crawler_bot_ua_key {
    0 "";
    1 $http_user_agent;
}

limit_req_zone $crawler_bot_ip_key zone=crawlip:10m rate=5r/m; # 5 requests per minute
limit_req zone=crawlip nodelay;
limit_req_zone $crawler_bot_ua_key zone=crawlua:10m rate=5r/m; # 5 requests per minute
limit_req zone=crawlua nodelay;

# limit_req_status 503; # default, service unavailable
limit_req_status 429; # too many requests
